[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a lecturer in Applied Statistics at the University of Aberdeen where I teach and conduct research in medicine and biology. My academic interests include spatio-temporal modelling, Bayesian heirarchical modelling, hidden Markov models, amongst others.\n\n\n\nBI3010 – 3rd year statistics course covering, R, linear and generalised linear models, ggplot2, basics of causal inference.\nPGR-GLM - A PhD GLM course\n\n\n\n\nHere are a few interactive apps I’ve developed:\n\nDistributions App\nAberdeen House Prices\nAberdeen Rental Prices\n\n\n\n\nYou can reach me at deon[dot]roos4[at]abdn.ac.uk or visit my github page."
  },
  {
    "objectID": "about.html#dr.-deon-roos",
    "href": "about.html#dr.-deon-roos",
    "title": "About",
    "section": "",
    "text": "I am a lecturer in Applied Statistics at the University of Aberdeen where I teach and conduct research in medicine and biology. My academic interests include spatio-temporal modelling, Bayesian heirarchical modelling, hidden Markov models, amongst others.\n\n\n\nBI3010 – 3rd year statistics course covering, R, linear and generalised linear models, ggplot2, basics of causal inference.\nPGR-GLM - A PhD GLM course\n\n\n\n\nHere are a few interactive apps I’ve developed:\n\nDistributions App\nAberdeen House Prices\nAberdeen Rental Prices\n\n\n\n\nYou can reach me at deon[dot]roos4[at]abdn.ac.uk or visit my github page."
  },
  {
    "objectID": "bi3010.html",
    "href": "bi3010.html",
    "title": "BI3010: Statistical Analysis of Biological Data",
    "section": "",
    "text": "This 3rd year undergraduate course introduces students to key statistical theory and data analysis techniques in biological sciences. It makes strong use of R and ggplot2 but aims to give a strong fundamental and theoretical understanding of statistical modelling and associated topics.\n\n\n\n\n\nWhy do we need statistics?\n\nIntroduction to linear models (LM) and hidden assumptions\n\nThe theory of effective data visualisation\n\nR and ggplot2\n\nLMs with a continuous predictor\n\nInterpreting LMs with a continuous predictor\n\nAssessing assumptions of LMs with a continuous predictor\n\nLMs with a categorical predictor\n\nInterpreting LMs with a categorical predictor\n\nAssessing assumptions of LMs with a categorical predictor\n\nLMs with multiple predictors\n\nConfounding and causality\n\nNull Hypothesis Significance Testing and P-values\n\nAn Information Criterion (AIC)\n\nAn introduction to GLMs\n\nPoisson GLMs\n\n\n\n\n\n\n\n\n\nWhat students learn"
  },
  {
    "objectID": "bi3010.html#overview",
    "href": "bi3010.html#overview",
    "title": "BI3010: Statistical Analysis of Biological Data",
    "section": "",
    "text": "This 3rd year undergraduate course introduces students to key statistical theory and data analysis techniques in biological sciences. It makes strong use of R and ggplot2 but aims to give a strong fundamental and theoretical understanding of statistical modelling and associated topics.\n\n\n\n\n\nWhy do we need statistics?\n\nIntroduction to linear models (LM) and hidden assumptions\n\nThe theory of effective data visualisation\n\nR and ggplot2\n\nLMs with a continuous predictor\n\nInterpreting LMs with a continuous predictor\n\nAssessing assumptions of LMs with a continuous predictor\n\nLMs with a categorical predictor\n\nInterpreting LMs with a categorical predictor\n\nAssessing assumptions of LMs with a categorical predictor\n\nLMs with multiple predictors\n\nConfounding and causality\n\nNull Hypothesis Significance Testing and P-values\n\nAn Information Criterion (AIC)\n\nAn introduction to GLMs\n\nPoisson GLMs\n\n\n\n\n\n\n\n\n\nWhat students learn"
  },
  {
    "objectID": "bi3010.html#tools-software",
    "href": "bi3010.html#tools-software",
    "title": "BI3010: Statistical Analysis of Biological Data",
    "section": "Tools & Software",
    "text": "Tools & Software\n\nR\nRStudio\nggplot2\n\n\n\\(\\leftarrow\\) Back to all courses"
  },
  {
    "objectID": "blog/2024-04-27-ucas-analysis.html",
    "href": "blog/2024-04-27-ucas-analysis.html",
    "title": "Undergraduate UCAS Applications and Acceptances Analysis",
    "section": "",
    "text": "Universities across the UK are in a pretty precarious position right now. After a host of issues, post 2020 has seen the number of students fall. The well seems to be drying up.\nAnd in some cases dramatically. Coventry University made a £54 million loss in 2023-24. Dundee was talking about having to fire ca. 600 employees because apparently the previous senior management team weren’t too good at maths.\nNow, possibly in combination with inflation and the “cost-of-living-crisis”, the long term viability of some universities is looking… Grim.\nThis got me thinking over the weekend as to why. What’s going on with high-school students that makes it less attractive to go to uni? I don’t know and I can’t answer this. I’d need to do a survey of school kids and universities would never pay to get evidence to make a decision. There’s no money remember? Unless it’s for an external consultancy team to tell you if you were fire red or earth green.\nWhat I can do is look at some larger scale patterns with some crude data. It’s something, I guess. I think most people would point to faltering university recruitment and see a clear line between Brexit (and latterly, the Tories not being the most welcoming to foreigners) and the loss of the pool of European applicants.\nBut if that’s the case, then we shouldn’t see any similar kinds of trends in UK students applying to UK universities, right? Their numbers should be relatively stable. If you’re in Englandshire, why would you care that you can’t go to Europe if you were planning to go to Englandshire University regardless?\nSo that’s the idea and my question. Is there something a bit more gloabl going on than just little Britain? If UK students are relatively stable, while EU applicants fall, then it’s probably mostly because of Brexit (and associated policies) that uni recruitment is falling. And strategies to target non-EU international students may well work. But if not? Well, that’s the more “global thing”, right?\n\n\nI’ll be skipping the data processing and going straight into the analysis. As such, I will only be using a few packages:\n\n\nCode\nlibrary(ggplot2)\nlibrary(mgcv)\n\n# DT is just for including data in the blog\nlibrary(DT)\n\n\nTo look into this I pulled some data off of the UCAS website. The UCAS site is a bit of a nightmare to navigate and an even bigger cluster fuck to figure out which of the seemingly gajillions of .csvs they’ve thrown into a zip file contain relevant information I want.\nRest assured, I have been through the valley of cluster fuckery and have emerged with a dataset. I won’t subject you to the Olympic levels of gymnastics I went through to get this but if you want a visual summary, watch The Book of Eli.\nHere’s the data. All clean ’n nice like.\n\n\nCode\nucas &lt;- read.csv(\"data/UCAS.csv\", stringsAsFactors = TRUE, header = TRUE)\ndatatable(ucas, options = list(pageLength = 10, scrollX = TRUE))"
  },
  {
    "objectID": "blog/2024-04-27-ucas-analysis.html#deets",
    "href": "blog/2024-04-27-ucas-analysis.html#deets",
    "title": "Undergraduate UCAS Applications and Acceptances Analysis",
    "section": "",
    "text": "I’ll be skipping the data processing and going straight into the analysis. As such, I will only be using a few packages:\n\n\nCode\nlibrary(ggplot2)\nlibrary(mgcv)\n\n# DT is just for including data in the blog\nlibrary(DT)\n\n\nTo look into this I pulled some data off of the UCAS website. The UCAS site is a bit of a nightmare to navigate and an even bigger cluster fuck to figure out which of the seemingly gajillions of .csvs they’ve thrown into a zip file contain relevant information I want.\nRest assured, I have been through the valley of cluster fuckery and have emerged with a dataset. I won’t subject you to the Olympic levels of gymnastics I went through to get this but if you want a visual summary, watch The Book of Eli.\nHere’s the data. All clean ’n nice like.\n\n\nCode\nucas &lt;- read.csv(\"data/UCAS.csv\", stringsAsFactors = TRUE, header = TRUE)\ndatatable(ucas, options = list(pageLength = 10, scrollX = TRUE))"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "My graveyard of ideas.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUndergraduate UCAS Applications and Acceptances Analysis\n\n\n\n\n\n\n`Apr 27, 2024`{=html}\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "courses.html#undergraduate-teaching",
    "href": "courses.html#undergraduate-teaching",
    "title": "Deon Roos",
    "section": "Undergraduate Teaching",
    "text": "Undergraduate Teaching\n\n  \n    BI3010: Statistical Analysis of Biological Data\n    This course covers key statistical concepts and theory for biological data using R.\n    Learn more"
  },
  {
    "objectID": "courses.html#postgraudate-teaching",
    "href": "courses.html#postgraudate-teaching",
    "title": "Deon Roos",
    "section": "Postgraudate Teaching",
    "text": "Postgraudate Teaching\n\n  \n    PGR Course: Generalised Linear Models\n    An advanced course on GLMs designed for postgrads across disciplines using R.\n    Learn more"
  },
  {
    "objectID": "cv-awards.html",
    "href": "cv-awards.html",
    "title": "Awards & Funding",
    "section": "",
    "text": "Best Student Presentation, University of Aberdeen\n2019\nTravelling waves as a form of spatio-temporal asynchrony\n\n\nBest Presentation, Iberian Vole Workshop, Porto\n2019\nSpatio-temporal asynchrony in a cyclic vole species\n\n\nSir Maitland Mackie Scholarship, University of Aberdeen\n2017\nFunding for agricultural research\n\n\nOutstanding BSc Zoology Student, University of Aberdeen\n2016\n\n\nPeople’s Trust Internship, PTES\n2016\nFunded research after BSc thesis\n\n\nCarnegie Summer Scholarship\n2015\nSupported BSc data collection\n\n\\(\\leftarrow\\) Back to CV Overview"
  },
  {
    "objectID": "cv-education.html",
    "href": "cv-education.html",
    "title": "Education",
    "section": "",
    "text": "PhD Ecology, University of Aberdeen\n2016 – 2021\n- Rodent pest population dynamics\n- Publications: Roos et al. (2019), Roos et al. (2022)\n\n\nBSc (Hons) Zoology, University of Aberdeen\n2012 – 2016\n- Graduated First Class\n\n\\(\\leftarrow\\) Back to CV Overview"
  },
  {
    "objectID": "cv-employment.html",
    "href": "cv-employment.html",
    "title": "Employment",
    "section": "",
    "text": "Lecturer in Applied Statistics, University of Aberdeen\nJanuary 2024 – Present\nAberdeen, Scotland\n- Leading and collaborating interdisciplinary research in applied statistics with real-world impact.\n- Teaching statistical theory and methods across undergraduate to PhD levels.\n- Assisting in research projects through the application of collaborator-specified statistical approaches.\n\n\nSenior Statistical Ecologist, Animal & Plant Health Agency\nMay 2022 – January 2024\nSand Hutton, England\n- Led statistics and mentoring, developing bespoke methods for policy-driven projects across multidisciplinary teams.\n\n\nTeaching Fellow, University of Aberdeen\nDec 2021 – May 2022\n- Coordinated and delivered a highly rated, fully online undergraduate statistics course with strong student engagement.\n\n\nResearch Fellow, University of Aberdeen\nJun 2021 – Feb 2022\n- Conducted international ecological research, including study design and simulation modeling for species management.\n\n\nTeaching Fellow, University of Aberdeen\nDec 2020 – May 2021\n- Course coordinator for undergraduate statistical course.\n\n\nOperating Department Support Worker, NHS Grampian\n2008 – 2012\nElgin, Scotland\n- Assisted in surgical procedures (non-sterile support).\n\n\\(\\leftarrow\\) Back to CV Overview"
  },
  {
    "objectID": "cv-phd.html",
    "href": "cv-phd.html",
    "title": "PhD Students",
    "section": "",
    "text": "Seungyeon Lee, University of Aberdeen\n2024 – Present\n- Integrated population models of tawny owls.\n\n\\(\\leftarrow\\) Back to CV Overview"
  },
  {
    "objectID": "cv-skills.html",
    "href": "cv-skills.html",
    "title": "Skills",
    "section": "",
    "text": "Programming: R, RShiny, basic Python\n\nStatistical Methods: Spatio-temporal modelling, Bayesian inference, Hidden Markov models, non-linear modelling, hierarchical modelling, simulation-based inference\n\nData Visualisation: ggplot2, gganimate, plotly, leaflet\n\nData Wrangling: comfortable with tidyverse and base R approaches; experience using SQL (SQLite via R)\n\nTeaching & Communication: In-person and online delivery, course coordination (ca. 150 students), course administration, interactive and accessible teaching of complex methods, supervision of postgraduate and PhD students\n\nReproducible Research: RMarkdown, Quarto, version control (Git), simulation workflows, reproducible project structure\n\nVersion Control: Git (via GitHub and GitHub Pages)\n\nMarkup & Documentation: RMarkdown, LaTeX, Quarto\n\nAPIs & Data Integration: Working with RESTful APIs, JSON parsing, ORCID integration\n\nLanguages: English (Fluent), Afrikaans (Fluent), Spanish (Basic)\n\n\\(\\leftarrow\\) Back to CV Overview"
  },
  {
    "objectID": "cv.html#sections",
    "href": "cv.html#sections",
    "title": "\nDeon Roos\n",
    "section": "Sections",
    "text": "Sections\n\n  \n    Employment\n    Work history across academia, statistical roles, and non-academic jobs.\n    View section\n  \n\n  \n    Education\n    Formal degrees and institutions attended.\n    View section\n  \n\n  \n    PhD Students\n    Supervision roles and ongoing projects.\n    View section\n  \n\n  \n    Awards & Funding\n    Recognition and research funding received.\n    View section\n  \n\n  \n    Skills\n    Technical, statistical, and communication expertise.\n    View section"
  },
  {
    "objectID": "explainers.html#models-concepts",
    "href": "explainers.html#models-concepts",
    "title": "Explainers",
    "section": "Models & Concepts",
    "text": "Models & Concepts\n\n\n\nIntroduction to GLMs\n\n \n\nBayesian Occupancy Models"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nI’m Deon Roos. I do stuff.\n",
    "section": "",
    "text": "I’m Deon Roos. I do stuff.\n\n\nCheck out my stuff to see what.\n\n\nLecturer | Scientist | Statistician\n\n\n\nload(“courses”) view(“output”) browse(“cv”)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\mu_i = f(\\rho_{0,i}) + f(\\rho_{1,i}) + f(\\rho_{2,i})\n\\]\n\\[\n\\rho_{j,i} = T + \\left(\\frac{1}{\\zeta_{j,i}}\\right) \\times D_{j,i}\n\\quad \\text{for } j \\in \\{0, 1, 2\\}\n\\]\n\\[\nD_{j,i} = -\\sqrt{(x_j - x_i)^2 + (y_j - y_i)^2}\n\\]\n\\[\n\\zeta_{j,i} = \\beta_0 + \\beta_1 \\times z_i\n\\]"
  },
  {
    "objectID": "pgr-glm.html",
    "href": "pgr-glm.html",
    "title": "PGR Course: Generalised Linear Models",
    "section": "",
    "text": "This advanced course focuses on the theory and application of Generalised Linear Models, tailored for PhD students and researchers. The course is designed to be non-field specific meaning it can be taken by geologists to marketers and any in between.\n\n\n\nIntroduction to statistical modelling and GLMs\n\nPoisson GLMs\n\nBinomial GLMs\n\nBernoulli GLMs"
  },
  {
    "objectID": "pgr-glm.html#overview",
    "href": "pgr-glm.html#overview",
    "title": "PGR Course: Generalised Linear Models",
    "section": "",
    "text": "This advanced course focuses on the theory and application of Generalised Linear Models, tailored for PhD students and researchers. The course is designed to be non-field specific meaning it can be taken by geologists to marketers and any in between.\n\n\n\nIntroduction to statistical modelling and GLMs\n\nPoisson GLMs\n\nBinomial GLMs\n\nBernoulli GLMs"
  },
  {
    "objectID": "pgr-glm.html#learning-objectives",
    "href": "pgr-glm.html#learning-objectives",
    "title": "PGR Course: Generalised Linear Models",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the core structure of GLMs\nFit models using R\nTranslate statistical equations into model syntax\nInterpret coefficients and results with confidence\nRecognise when assumptions are violated"
  },
  {
    "objectID": "pgr-glm.html#course-website",
    "href": "pgr-glm.html#course-website",
    "title": "PGR Course: Generalised Linear Models",
    "section": "Course Website",
    "text": "Course Website\n🔗 Visit the course website\n\n\\(\\leftarrow\\) Back to all courses"
  },
  {
    "objectID": "publications.html#web-applications",
    "href": "publications.html#web-applications",
    "title": "Deon Roos",
    "section": "Web Applications",
    "text": "Web Applications\n\n\n\nStatistical Distributions\n\n \n\nPredicting House Prices\n\n \n\nPredicting Rent Prices"
  },
  {
    "objectID": "publications.html#peer-reviewed-papers",
    "href": "publications.html#peer-reviewed-papers",
    "title": "Deon Roos",
    "section": "Peer-reviewed papers",
    "text": "Peer-reviewed papers\nCristiano Tiberi, Sarah Beatham, Julia Coats, Izzy Rochester, Deon Roos, Riccardo Primi, Andrea Vitali, Giovanna Massei (2025). An assessment of whether age, sex, and reproductive status affect bait uptake by grey squirrels, Journal of Wildlife Management.Tiago Crispim-Mendes, Deon Roos, Clara Mendes Ferreira, Joana Paupério, João Paulo Silva, Sérgio Godinho, Paulo Célio Alves, António Mira, Pedro Beja, Xavier Lambin, Ricardo Pita (2024). Patch spatial attributes and time to disturbance affect the emergence of source local populations within ephemeral habitats, Ecological Modelling.Ijeoma Nnenna Okoliegbe, Sara Aly Abdelfatah Sharaf, Susanth Alapati, Deon Roos, Antonio Ribeiro, Istifanus Nkene, Daniele Ghezzi, Stuart Reid, Victoria Austin, Dolapo Ayansina, Rebecca Wilson, Tanzeel Ur-Rehman, Benjamin J Parcell, Ian Mellor, Charis A. Marwick, Marco Oggioni, Karolin Hijazi (2024). Effects of universal versus targeted chlorhexidine skin decolonisation on the clinical and molecular epidemiology of Staphylococcus epidermidis bloodstream infections in intensive care, SSRN Preprints with The Lancet.J. Colomer, G. Massei, Deon Roos, C. Rosell, J. D. Rodríguez-Teijeiro (2024). What drives wild boar density and population growth in Mediterranean environments?, Science of the Total Environment.Deon Roos, Constantino Caminero‐Saldaña, David Elston, François Mougeot, María Carmen García‐Ariza, Beatriz Arroyo, Juan José Luque‐Larena, Francisco Javier Rojo Revilla, Xavier Lambin (2022). From pattern to process? Dual travelling waves, with contrasting propagation speeds, best describe a self‐organised spatio‐temporal pattern in population growth of a cyclic rodent, Ecology Letters.James Slingsby, Beth E. Scott, Louise Kregting, Jason McIlvenny, Jared Wilson, Ana Couto, Deon Roos, Marion Yanez, Benjamin Williamson (2021). Surface Characterisation of Kolk-Boils within Tidal Stream Environments Using UAV Imagery, Journal of Marine Science and Engineering.Roos, D., Caminero Saldaña, C., Arroyo, B., Mougeot, F., Luque-Larena, J.J., Lambin, X. (2019). Unintentional effects of environmentally-friendly farming practices: Arising conflicts between zero-tillage and a crop pest, the common vole (Microtus arvalis), Agriculture, Ecosystems and Environment."
  },
  {
    "objectID": "publications.html#textbooks",
    "href": "publications.html#textbooks",
    "title": "Deon Roos",
    "section": "Textbooks",
    "text": "Textbooks\nA Douglas, D Roos, F Mancini, A Couto, D Lusseau. An introduction to R."
  },
  {
    "objectID": "stm-explainer.html",
    "href": "stm-explainer.html",
    "title": "Structural Topic Models",
    "section": "",
    "text": "Hey Grace,\nI’ve written this page especially for you and your honours project. I’ve aimed to keep it accessible, covering both the core theory behind the stats you’ll use (Structural Topic Models, STMs) but also how to actually implement them. That said, the theory can get complex at times, and I’m still learning it myself! (It’s also surprisingly hard to find good, clear explanations online.) It took me a while to make sense of the stats, so don’t worry if it takes some time. Be patient with yourself.\nTo be clear, this page isn’t meant to replace our meetings or turn me into a hands-off “supervisor.” It’s a resource you can return to whenever you need a refresher or some help getting unstuck.\nHopefully, this helps you get a handle on the method, but let me know if anything is confusing. It probably won’t answer every question, and I won’t be offended if you want to toss it in a bonfire. Just flag anything that’s unclear, and we’ll work through it together."
  },
  {
    "objectID": "stm-explainer.html#what-is-a-structural-topic-model",
    "href": "stm-explainer.html#what-is-a-structural-topic-model",
    "title": "Structural Topic Models",
    "section": "What is a Structural Topic Model?",
    "text": "What is a Structural Topic Model?\nA Structural Topic Model (STM) is a type of analysis that allows us to explore large sets of text documents and identify what the common themes are; called topics. Just like you did in BI3010, you can also include covariates (also called explanatory variables) to see if that makes a topic may be more or less prevalent.\n\nGrace, in your case, this might include things like how date (i.e. how has coverage of lynx changed over time), and if the illegal release of lynx (and maybe their interaction) may have changed which topics are more or less prevelant. For example, did negative topics become more common in the media after the illegal release compared to before?\n\nSTMs are a fairly complex beast, with lots of new ideas. One of these new ideas that I won’t explain in this document is Bayesian statistics. Luckily, I have written another set of documents that explain the general theory of this, which you are welcome and encouraged to read through. Although STMs, as implemented in the R package stm, use the Bayesian statistical framework, you can’t actually interact with it, so it’s not crucial to understand in this case. However, I would recommend trying to wrap your head around it, as it’s a piece of knowledge that may make you highly employable.\nWith that said, let’s go over, conceptually, what Structural Topic Models are going.\n\nWe begin by gathering a corpus. This is a collection of documents, like newspaper articles. Our objective is to learn something about the corpus.\nWe assume that within each document, there can exist multiple topics. Topics are the “themes” that the document covers; things like “Lynx are bad and we shouldn’t release them” or “Lynx are good and we should release them”.\nThese topics are latent, which means “hidden” or “unobserved” (newspapers don’t add a sticker on each article to say what the theme is afterall) and we want to use the STM to identify them and to see which are most prevalent.\nWe state how many theme we think there are. This might be 5 or it might be 200. This is a choice we make. (There are some tools that can help make this choice.)\nWithin each document we consider each word. We assume that each word is associated with one of these topics with differing probabilities. For example, if there is a topic for “Lynx are bad”, then we might expect that “livestock” has a 90% chance of belonging to this topic, while “rewilding” only has a 0.5% chance.\nEach topic will have a distribution of words associated with it, each with their own probability to belong to that topic.\n\nSo our objective then, is to identify different topics, and which words tend to categorise those topics. This is what we’re, fundamentally, trying to do in an STM."
  },
  {
    "objectID": "stm-explainer.html#what-does-an-stm-look-like",
    "href": "stm-explainer.html#what-does-an-stm-look-like",
    "title": "Structural Topic Models",
    "section": "What does an STM look like?",
    "text": "What does an STM look like?\nLet’s start with a simple way to visualise the data and output of an STM (apologies for the generative AI image):\n\nThe things to take away from this are to highlight that \\(d\\) is just the current document you are looking at. \\(\\theta_k\\) describes the relative proportion of a document that is dedicated to topic \\(k\\) (e.g. in the above figure we have three topics, called A, B and C). These topics are determined by the word (\\(w\\), given all words \\(n\\) used in the document \\(d\\)) within them, that appears in the topic (\\(k\\)) with probability \\(\\beta\\).\nThat’s the simplified version. If we dive into the details, things get a bit more complex."
  },
  {
    "objectID": "stm-explainer.html#the-equations",
    "href": "stm-explainer.html#the-equations",
    "title": "Structural Topic Models",
    "section": "The equations",
    "text": "The equations\nWe’ll go through this step-by-step because the estimation process in structural topic modeling is complex (but powerful).\n\n1. Topic proportions\nFor each document \\(d\\) that we have, with covariates \\(\\vec{X}_d\\), there is a corresponding vocabulary size of \\(\\vec{V}\\), given \\(K\\) topics, we’re going to fit a GLM that uses a multivariate normal distribution to estimate which topic is present in a document (note that the \\(\\vec{}\\) is shorthand for vector, or a column of data):\n\\[\n\\vec{\\theta} |X_{d\\gamma}, \\Sigma \\sim \\mathcal{MVNorm}(\\boldsymbol{X_d} \\boldsymbol{\\Gamma}, \\boldsymbol\\Sigma)\n\\]\n\nA multivariate normal distribution is like several normal distributions stacked together. So, instead of having just one mean and one variance, you have a mean and variance for each topic. The covariance matrix \\(\\Sigma\\) (which is the variance) also tells you how topics tend to co-occur, for example, maybe “Lynx are bad” often appears alongside “Predator control”.\n\nwhere \\(\\vec{X}_d\\) is a 1-by-\\(p\\) vector (your covariates), \\(\\gamma\\) is a \\(p\\)-by-(\\(K-1\\)) matrix of coefficients (this is a way to describe all the parameters, \\(p\\), in the model) and \\(\\boldsymbol{\\Sigma}\\) is a (\\(K-1\\))-by-(\\(K-1\\)) covariance matrix.\n\n\n2. Topic-Word distributions\nAssume you included a document-level content covariate \\(y_d\\) (e.g. Politically Left versus Politically Right newspaper), we can form a document-specific distribution of words (as a vector, or “column” of numbers), called \\(\\boldsymbol{\\beta}\\), which represents each topic (\\(k\\)) by using:\n\nThe baseline word distribution (\\(m\\), i.e. how common is this word across all documents),\nThe topic specific deviation \\(\\boldsymbol{\\kappa}^{(t)}_k\\) (i.e. is that word more or less common in topic \\(k\\))\nThe covariate group deviation \\(\\boldsymbol{\\kappa}^{(c)}_{y_d}\\) (i.e. is that word more or less common in Politically Left or Right newspapers),\nAnd the interaction between the two \\(\\boldsymbol{\\kappa}^{(i)}_{y_d,k}\\) if we want one\n\nwhich we can estimate by doing:\n\\[\n\\vec{\\beta}_{d,k} \\propto exp(\\vec{m} + \\vec{\\kappa}^{(t)}_k + \\vec{\\kappa}^{(c)}_{y_d} + \\vec{\\kappa}^{(i)}_{y_d,k})\n\\]\n\nRead this as saying “the probability, \\(\\beta\\), to see a given unique word in document \\(d\\), in topic \\(k\\) is proportional to (the \\(\\propto\\) symbol) how common it is in general, as well as how common it is in the given topic and/or group”\n\nThis gives:\n\\[\n\\vec{\\beta}_{d,k} = [\\beta_{d,k,1}, \\beta_{d,k,2}, ..., \\beta_{d,k,V}]\n\\]\nwhere \\(\\vec{\\beta}_{d,k}\\) is a vector that contains the probability to see a given unique word [the \\(_{1,2,...,V}\\) bit] in a topic (\\(k\\)), in a document (\\(d\\))).\n\n\nEstimating \\(\\vec{\\beta}_{d,k}\\)\nKeep in mind that \\(\\vec{\\beta}_{d,k}\\) should be a probability. But to figure it out we start by estimating the rate that at which we see each unique word (\\(v\\)) across the entire corpus in multiple Poisson GLM (one for each unique word):\n\\[\ny_v \\sim Poisson(\\lambda_v) \\\\\nlog(\\lambda_v) = m_v + \\kappa^{(t)}_{k,v} + \\kappa^{(c)}_{y_d,v} + \\kappa^{(i)}_{y_d,k,v}\n\\]\nHere, \\(y_v\\) is the observed count of word \\(v\\). Remember from BI3010 that a Poisson GLM estimates a rate but here we need a probability. To do that, we take the estimated rate (\\(\\lambda\\)) for word \\(v\\) and divide it by the sum all of the \\(\\lambda\\)s of all the other Poisson GLMs to get a probability (e.g. if we see the word lynx 100 times but we see a total of 500 words, then the probability to see the word lynx is \\(\\frac{100}{500} = 0.2 = 20\\%\\). We do this by:\n\\[\n\\beta_{d,k,v} = \\frac{\\lambda_v}{\\sum\\lambda_{v'}}\n\\]\n\nA small note here. Normally you’d want to estimate this by using a multinomial GLM, which estimates the probability of an event happening - like seeing the word lynx - but when you have lots of different words. The problem occurs when you have hundreds of thousands of unique words. In that case a multinomial model can take far too long to fit. That’s why stm uses a Poisson model for each unique word which takes these rates and converts them to probabilities.\n\n\n\nEstimating topic assignment and words\nNow that we’ve estimated the topic proportions \\(\\vec{\\theta}_d\\) and the topic-word distributions \\(\\vec{\\beta}_{d,k}\\), we can now estimate the latent variables that explain how each word was chosen.\nFor each word in the document (which we can write as \\(n \\in \\{1,...,N_d\\}\\), or “for each word that is in all words from the first to the last”) :\n\nEstimate the topic by fitting a multinomial GLM, based on the probabilities in the vector \\(\\vec{\\theta}_d\\):\n\\[\nz_{d,n}|\\vec{\\theta_d} \\sim Multinomial(\\vec{\\theta_d})\n\\]\nThen conditional on the topic, we fit another multinomial GLM to estimate which word is most likely to appear in that topic:\n\\[\nw_{d,n}|z_{d,n}, \\vec{\\beta}_{d,k=z_{d,n}} \\sim Multinomial(\\vec{\\beta}_{d,k=z_{d,n}})\n\\]\n\nAnd that’s it. Suuuuuper simple, right? For transparency, I spent about three days going over material trying to make sense of the literature, in part because quantitative social scientists use very different terminology and a lot of the material I found glossed over the details, making it frustratingly hard to understand what an STM is actually doing. (But also a hell of a lot of fun)."
  },
  {
    "objectID": "stm-explainer.html#plate-notation",
    "href": "stm-explainer.html#plate-notation",
    "title": "Structural Topic Models",
    "section": "Plate notation",
    "text": "Plate notation\nIf the above equations were too much, there’s another way to describe how the model works; more visual and less algebraic. It doesn’t given the nuts-and-bolts but it might help to give an intuition.\nTo do so, we can use plate notation. These are diagrams that describe how different parts of the model relate to each other.\n\n\nCode\nlibrary(DiagrammeR)\n\ngrViz(\"\ndigraph stm {\n  graph [layout = dot, rankdir = LR]\n\n  # Nodes\n  Σ [shape=circle, label='Σ', style=dashed]\n  Γ [shape=circle, label='Γ', style=dashed]\n  X [shape=circle, label='X']\n  κ [shape=circle, label='κ']\n  θ [shape=circle, label='θ', style=dashed]\n  z [shape=circle, label='z', style=dashed]\n  w [shape=circle, label='w']\n  β [shape=circle, label='β', style=dashed]\n\n  # Edges\n  Σ -&gt; θ\n  Γ -&gt; θ\n  X -&gt; θ\n  θ -&gt; z\n  z -&gt; w\n  β -&gt; w\n  κ -&gt; β\n\n  # Outer plate: D\n  subgraph cluster_D {\n    label = 'D'\n    style = 'solid'\n    X; θ; β; κ;\n\n    # Nested plate: N\n    subgraph cluster_N {\n      label = 'N'\n      style = 'solid'\n      z; w;\n    }\n  }\n}\n\")\n\n\n\n\n\n\nWhere:\n\nNodes: Circles represent variables. Dashed circles mean they are latent (a variable we have to estimate), while solid circles means they are observed data.\nPlates: Rectangle indicate repetition:\n\n\\(D\\): Each node is relevent for each document\n\\(N\\): Each node is relevant for each word (and because \\(N\\) is within \\(D\\), also for each document)\n\n\nAnd where the variables in the plate notation are:\n\n\\(X\\) - Document level covariates (e.g. date of publication, political leaning)\n\\(\\Gamma\\) - Coefficients that determine how \\(X\\) affects topic proportions\n\\(\\Sigma\\) - The covariance matrix between topics (models topic co-occurence)\n\\(\\theta\\) - The estimated topic proportion (which sums to 1)\n\\(z\\) - Estimated topic assignment for word \\(n\\) in document \\(d\\)\n\\(w\\) - The actual observed word (e.g. lynx)\n\\(\\beta\\) - The estimated word distribution for topic \\(k\\)\n\\(\\kappa\\) - Document level content covariate (e.g. political group)\n\n\nWhat’s in the box?\n\\(\\beta\\) is the topic-word matrix, of dimension \\(\\mathbf{K}\\times \\mathbf{V}\\), where each row \\(\\beta_k\\) is a probability distribution over the vocabulary (words) for topic \\(k\\) (each row in the \\(\\beta\\) matrix below). \\(\\beta\\) can be estimated from the data or modeled as a logit-linear function of content covariates.\nFor \\(\\beta\\) it’s actually a topic-word matrix \\(\\beta\\): \\(\\mathbf{K} \\times \\mathbf{V}\\)\n\\[\n\\begin{array}{c|cccc}\n& \\text{predator} & \\text{policy} & \\cdots & \\text{illegal} \\\\\n\\hline\n\\text{Topic } 1 & \\beta_{1,1} & \\beta_{1,2} & \\cdots & \\beta_{1,V} \\\\\n\\text{Topic } 2 & \\beta_{2,1} & \\beta_{2,2} & \\cdots & \\beta_{2,V} \\\\\n\\text{Topic } 3 & \\beta_{3,1} & \\beta_{3,2} & \\cdots & \\beta_{3,V} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\text{Topic } K & \\beta_{K,1} & \\beta_{K,2} & \\cdots & \\beta_{K,V}\n\\end{array}\n\\]\nAnd for \\(\\theta\\), it’s a document-topic matrix: \\(\\mathbf{D} \\times \\mathbf{K}\\)\n\\[\n\\begin{array}{c|cccc}\n& \\text{Topic 1} & \\text{Topic 2} & \\cdots & \\text{Topic } K \\\\\n\\hline\nDoc1 & \\theta_{1,1} & \\theta_{1,2} & \\cdots & \\theta_{1,K} \\\\\nDoc2 & \\theta_{2,1} & \\theta_{2,2} & \\cdots & \\theta_{2,K} \\\\\nDoc3 & \\theta_{3,1} & \\theta_{3,2} & \\cdots & \\theta_{3,K} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\nD & \\theta_{D,1} & \\theta_{D,2} & \\cdots & \\theta_{D,K}\n\\end{array}\n\\]"
  },
  {
    "objectID": "stm-explainer.html#load-packages-and-data",
    "href": "stm-explainer.html#load-packages-and-data",
    "title": "Structural Topic Models",
    "section": "Load Packages and Data",
    "text": "Load Packages and Data\n\n\nCode\nlibrary(stm)\n\n\nstm v1.3.7 successfully loaded. See ?stm for help. \n Papers, resources, and other materials at structuraltopicmodel.com\n\n\nCode\nlibrary(tm)\n\n\nLoading required package: NLP\n\n\nCode\nlibrary(ggplot2)\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:NLP':\n\n    annotate\n\n\nCode\n# Load the data\ndata &lt;- read.csv(\"data/poliblogs2008.csv\", stringsAsFactors = FALSE)\n\n# Display just the first few rows\nhead(data, 5)\n\n\n  X\n1 1\n2 2\n3 3\n4 4\n5 5\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    documents\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       After a week of false statements, lies, and dismissive apologies, Pakistani President Pervez Musharraf now says that he is disatisfied with the probe into former Prime Minister Benazir Bhutto's death and is asking Scotland Yard for help:\"One should not give a statement that's 100 percent final. That's the flaw that we suffer from,\" Musharraf said at a news conference, noting that more evidence was emerging about the attack. \"We needed more experience, maybe more forensic and technical experience that our people don't have. Therefore I thought Scotland Yard may be more helpful.\" Musharraf said he also reached out to British investigators for assistance to dispel accusations that Pakistan's military or intelligence services were involved. \"We don't mind going to any extent, as nobody is involved from the government or agency side,\" he said. Speaking a week after Bhutto's assassination in a shooting and suicide bombing, Musharraf denied there had been a security lapse and implied that Bhutto, who was greeting supporters through the sunroof of her armored vehicle at the time of the attack, was partly responsible. \"Who is to be blamed for her coming out (of) her vehicle?\" he asked, adding that others in the vehicle had not been hurt in the attack.When in doubt, blame the victim.Reports in the immediate aftermath of the bombing said that as far back as November, Bhutto believed Musharraf was deliberately withholding security forces that could have made her safer. Unless he feared Bhutto more than the street riotors, I doubt whether that was really true. More likely, he didn't trust the army to protect her. And when she requested that Musharraf allow her to use western private security firms, he refused.I don't think Musharraf wanted Bhutto dead. But I think he is just too weak and indecisive to have done what was needed to protect her.\n2 I honestly don't know how either party's caucus results will play out tonight. Usually, you can get a good idea of perhaps not a winner but at least you can figure out who's up, who's down, and who's on life support.Not with the Iowa Caucuses. Races in both parties are just too close to call. So many variables. So much volatility among the voters. And the polls are whacky.As an example, here are the final two polls out on Iowa. First, ARG:Mike Huckabee 29% (23%) Mitt Romney 24% (32%) Fred Thompson 13% (7%) John McCain 11% (11%) Rudy Giuliani 8% (6%) Ron Paul 6% (6%) Duncan Hunter 4% (2%) Undecided 4% (11%) (Number in parentheses is from ARG survey taken last week)The spread between Huckabee and Romney is the margin of error which means they are virtually tied. Note Thompson's huge bump. Is he surging? Many think so although he probably doesn't have enough juice to catch either front runner for second place. But a strong third sends him along the campaign trail - despite what you might have heard about him dropping out. (Fred and his staff are denying the filthy rumor every chance they get.)Meanwhile, Zogby's daily tracking poll (three day rolling average) tells a little different story:* Huckabee - 31%* Romney - 25%* Thompson - 11%*McCain -10%Here the Huckster opens up a slight lead on Romney with Thompson and McCain far back in the pack.On the Democratic side, Obama has sprinted into the lead:Democrat Barack Obama continued his upward momentum through the evening before the Iowa caucuses, capturing the lead ahead of rivals John Edwards and Hillary Clinton.. Meanwhile, Republican Mike Hucakbee widened his lead over Mitt Romney down the stretch, the newest and last Reuters/C–SPAN/Zogby daily telephone tracking poll in Iowa shows. Obama broke through the 30% barrier for the first time, gaining 31% support after another strong day leading up to the caucuses. But more dramatic was Clinton’s four-point drop in this last day of tracking. Edwards moved into second place by himself after another day where he steadily gained ground. This fifth and final daily tracking poll was conducted using live telephone operators in the Zogby call center in Upstate New York. Edwards finished this Zogby daily tracking in Iowa in the same place as four years ago, when Zogby correctly identified the finishing order of the candidates in that caucus.Hillary Clinton has been playing down her chances the last 48 hours and could very well finish 3rd.All of this matters little in the end. The process of caucusing is complicated for the Democrats and it is possible for any of the top three candidates to win or come in third.We'll see by midnight tonight central time.\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          While we stand in awe of the willingness of our troops in Iraq to sacrifice themselves for the Nation, the fewer that are required to do so, the better.  And the news on that front is good.  As can be seen in the chart below, our military deaths in December dropped to 23 from 37 in November.  December deaths are down over 80% (82%) from May's peak this year of 126.  Assuming this reflects a permanent change in the correlation of forces in Iraq - and it is likely that it does, although we cannot be certain of it - it reflects a tremendous achievement on the part of General Petraeus, since this is the result not of retreating from our objectives in Iraq but of advancing toward them - of executing the mission.What of Iraqi deaths?  Iraqi security forces and civilian fatalities are also down in December from November. Iraqi deaths are down only by a small amount - from 560 in November to 534 in December, although that difference is not small if you are one of the ones who are now still alive.  And the decline from this year's peak in February of 3,014 is a drop of 82%(!).Are we out of the woods in Iraq?  It would seem not.  We have General Odierno's estremely disturbing cri de coeur  at the end of November, which we can assume was endorsed by his chief, General Petraeus.  So far as we know, General Odierno's point \"A window of opportunity has opened for the government to reach out to its former foes, said Army Lt. Gen. Raymond T. Odierno, the commander of day-to-day U.S. military operations in Iraq, but ‘it's unclear how long that window is going to be open.'\"has not been resolved.  While some economic indicators, such as the Iraq Stock Exchange and the value of the Iraqi dinar, are showing real strength, the status of the estimated 4 million internal and external refugees remains open, as does the high unemployment rate, estimated at over 40%.  But the fatalities figures are good news on the war-fighting front and we don't want to miss them.  Success doesn't always announce itself.   It's important not to miss it when it is achieved.\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                These pages recently said goodbye to global warming.  Ironically, the current spell of global warming, such as it is, can be expected to end just as the Kyoto treaty ends in 2012, but having nothing to do with reduced emissions from fossil fuels.  For the remainder of this century, it will be global cooling we'll have to worry about, according to highly credentialed Russian scientist, Dr. Oleg Sorokhtin.Dr. Sorokhtin, Merited Scientist of Russia and fellow of the Russian Academy of Natural Sciences, is staff researcher of the Oceanology Institute.  He explains the recent warming as a natural trend.\"Earth is now at the peak of one of its passing warm spells. It started in the 17th century when there was no industrial influence on the climate to speak of and no such thing as the hothouse effect. The current warming is evidently a natural process and utterly independent of hothouse gases.\"So what will happen in the future?\"Astrophysics knows two solar activity cycles, of 11 and 200 years. Both are caused by changes in the radius and area of the irradiating solar surface. The latest data, obtained by Habibullah Abdusamatov, head of the Pulkovo Observatory space research laboratory, say that Earth has passed the peak of its warmer period, and a fairly cold spell will set in quite soon, by 2012. Real cold will come when solar activity reaches its minimum, by 2041, and will last for 50-60 years or even longer.\"Physical and mathematical calculations predict a new Ice Age. It will come in 100,000 years, at the earliest, and will be much worse than the previous. Europe will be ice-bound, with glaciers reaching south of Moscow.\"The high standing of Dr. Sorkhtin and the inherent plausibility of his argument that climate will continue to follow the same basic causal factor, solar activity, make this another heavy blow to the heavy breathing of the global warming alarmists, who insist there is no argument at all.\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       A US report shows how the enemy controlled the information on the battlefield in Fallujah and used this to force the US and Iraqi forces out, in the first battle there. The Belmont Club points out UPI coverage of the report by Shaun Waterman. Here is how the enemy worked: First they kidnapped reporters from major Western news sources, driving them out of the city, and leaving only Al Jazeera, Al Arabiya and local stringers controlled by the enemy as the sole sources of news. When the US returned with many embedded journalists and cut the enemy's information monopoly we won.These figures demonstrate how the insurgency purposely drove the press from the field to recreate the information monopoly they found so advantageous in the opening days of the First Fallujah, when only journalists from Al Jazeera and Al Arabiya were reporting from the scene. The kidnapping campaign compelled news outlets to rely on stringers who could then be controlled by the insurgency and who could be counted on to miraculously stumble on photo opportunities showing insurgents in action, such as the Pulitzer Prize winning photograph of an Iraqi election worker being killed on Haifa Street. The effective riposte again turned out to be finding ways to break the reportorial stranglehold the enemy had established. The information blockade runners turned out to be bloggers and journalists embedded in the military, of whom Michael Yon is perhaps the most famous. The Iraqi bloggers were protected by their anonymity and the embedded journalists were protected by coalition troops. These reporters outflanked the wall of \"access journalism\" which was gradually restricting the majors and created alternative sources of reportage. Although few in number these blockade runners played a pivotal role in penetrating the \"bodyguard of lies\" with which al-Qaeda and the Sunni insurgency had surrounded itself.\n           docname       rating day blog\n1 at0800300_1.text Conservative   3   at\n2 at0800300_2.text Conservative   3   at\n3 at0800300_3.text Conservative   3   at\n4 at0800300_4.text Conservative   3   at\n5 at0800300_5.text Conservative   3   at"
  },
  {
    "objectID": "stm-explainer.html#preprocess-text",
    "href": "stm-explainer.html#preprocess-text",
    "title": "Structural Topic Models",
    "section": "Preprocess Text",
    "text": "Preprocess Text\nThe first important stage in the analysis, before we get to the modelling, is to process the text. There’s apparently a lot of debate in the social sciences over whether or not to do some of these steps. I won’t lie. I’m no expert so I can’t give any meaningful advice here, other than to do some of your own research and decide what you want to do.\nImagine we have this sentence:\n\nA lynx was released today in Edinburgh. Locals are said to have fed it Whiskers cat food and offered it some buckfast.\n\nAfter text processing, this becomes:\n\nlynx was released today in edinburgh\nlocals are said to have fed it whiskers cat food and offered it some buckfast\n\n\n\nCode\nprocessed &lt;- textProcessor(data$documents, metadata = data)\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout &lt;- prepDocuments(processed$documents, processed$vocab, processed$meta)\n\n\nRemoving 83198 of 123990 terms (83198 of 2298953 tokens) due to frequency \nYour corpus now has 13246 documents, 40792 terms and 2215755 tokens.\n\n\nCode\ndocs &lt;- out$documents\nvocab &lt;- out$vocab\nmeta &lt;- out$meta\n\n\n\n\nCode\nplotRemoved(processed$documents, lower.thresh = seq(1, 200, by = 100))"
  },
  {
    "objectID": "stm-explainer.html#choosing-k-number-of-topics",
    "href": "stm-explainer.html#choosing-k-number-of-topics",
    "title": "Structural Topic Models",
    "section": "Choosing K (Number of Topics)",
    "text": "Choosing K (Number of Topics)\n\n\nCode\n# searchK(docs, vocab, K = c(10, 15, 20, 25), data = meta)\n\n\nExpectation-Maximiation equivalent to brute forcing MCMC - give it a function and iteratively optimise it until threshold of error reached. Priors locked (I think)"
  },
  {
    "objectID": "stm-explainer.html#fit-stm-model-1-no-covariates",
    "href": "stm-explainer.html#fit-stm-model-1-no-covariates",
    "title": "Structural Topic Models",
    "section": "Fit STM – Model 1 (No Covariates)",
    "text": "Fit STM – Model 1 (No Covariates)\n\n\nCode\nmodel1 &lt;- stm(documents = docs,\n              vocab = vocab,\n              K = 20,\n              data = meta,\n              init.type = \"Spectral\", \n              verbose = FALSE)\n\n\n\nExplore Model 1\n\n\nCode\nplot(model1, type = \"summary\")\nlabelTopics(model1)\nfindThoughts(model1, texts = meta$documents, n = 2, topics = 3)"
  },
  {
    "objectID": "stm-explainer.html#fit-stm-model-2-with-covariates",
    "href": "stm-explainer.html#fit-stm-model-2-with-covariates",
    "title": "Structural Topic Models",
    "section": "Fit STM – Model 2 (With Covariates)",
    "text": "Fit STM – Model 2 (With Covariates)\n\n\nCode\nmodel2 &lt;- stm(documents = docs,\n              vocab = vocab,\n              K = 20,\n              prevalence = ~ rating + s(day, df = 5),\n              data = meta,\n              init.type = \"Spectral\",\n              verbose = FALSE)\n\n\n\nExplore Model 2\n\n\nCode\nplot(model2, type = \"summary\")\nlabelTopics(model2, topics = c(3, 7, 20))\nfindThoughts(model2, texts = meta$documents, n = 2, topics = 3)$docs[[1]]"
  },
  {
    "objectID": "stm-explainer.html#estimate-and-plot-covariate-effects",
    "href": "stm-explainer.html#estimate-and-plot-covariate-effects",
    "title": "Structural Topic Models",
    "section": "Estimate and Plot Covariate Effects",
    "text": "Estimate and Plot Covariate Effects\n\n\nCode\neffect_model &lt;- estimateEffect(1:20 ~ rating + s(day), model2,\n                               meta = meta, uncertainty = \"Global\")\nsummary(effect_model, topics = 3)\n\n\n\n\nCode\nplot(effect_model, \"day\", method = \"continuous\", topics = 7,\n     printlegend = FALSE, xlab = \"Time (2008)\", xaxt = \"n\")\n\nmonthseq &lt;- seq(from = as.Date(\"2008-01-01\"), to = as.Date(\"2008-12-01\"), by = \"month\")\nmonthnames &lt;- months(monthseq)\naxis(1, at = as.numeric(monthseq) - min(as.numeric(monthseq)), labels = monthnames)\n\n\n\n\nCode\nplot(effect_model, covariate = \"rating\", topics = 3, method = \"difference\",\n     cov.value1 = \"Liberal\", cov.value2 = \"Conservative\",\n     xlab = \"More Liberal ... More Conservative\",\n     main = \"Topic 3: Difference by Political Rating\")"
  },
  {
    "objectID": "stm-explainer.html#summary",
    "href": "stm-explainer.html#summary",
    "title": "Structural Topic Models",
    "section": "Summary",
    "text": "Summary\n\nSTM helps uncover underlying topics in a collection of documents.\nDocument-level metadata can be used to model how topic proportions vary.\nThe logistic normal plays a similar role to a logit link in GLMs.\nSTM is hierarchical: topic use varies across documents; topics generate words."
  }
]